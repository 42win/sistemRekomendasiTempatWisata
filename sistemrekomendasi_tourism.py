# -*- coding: utf-8 -*-
"""sistemRekomendasi_Tourism.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/111xvJtzJHn8VV8SvOu4wFlV1LxNkM4x7

# Sistem rekomendasi tempat wisata di indonesia

## Data Collecting

- import library
  - drive
  - numpy
  - pandas
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""- define files path"""

s_tourism_rating = f'drive/MyDrive/ML/ML Terapan/tourism_recomendation/tourism_rating.csv'
s_tourism_id = f'drive/MyDrive/ML/ML Terapan/tourism_recomendation/tourism_with_id.csv'

s_tourism_user = f'drive/MyDrive/ML/ML Terapan/tourism_recomendation/user.csv'

"""- load file"""

dat_tourism_rating = pd.read_csv(s_tourism_rating,sep=',')
dat_tourism_id = pd.read_csv(s_tourism_id,sep=',')

dat_tourism_user = pd.read_csv(s_tourism_user,sep=',')

"""## Data understanding

dataset yang digunakan memiliki 4 file yaitu

- tourism_with_id.csv yang berisi informasi tempat wisata di 5 kota besar di indonesia yang berjumlah 437 baris
- user.csv which berisi data dummy user untuk membuat fitur rekomendasi berdasarkan user yang berjumlah 300 baris.
- tourism_rating.csv berisi 3 kolom yaitu user,tempat dan rating yang berfungsi untuk membuat sistem rekomendasi rating yang berjumlah 10000
- package_tourism.csv berisi rekomendasi tempat berdasarkan waktu, biaya, dan rating yang berjumlah 100 baris

namun pada project ini hanya akan digunakan 2 dataset yaitu tourism_with_id dan tourism_rating

Tahap eksplorasi penting untuk memahami variabel-variabel pada data serta korelasi antar variabel. Pemahaman terhadap variabel pada data dan korelasinya akan membantu kita dalam menentukan pendekatan atau algoritma yang cocok untuk data kita. Idealnya, kita melakukan eksplorasi data terhadap seluruh variabel. Namun, pada proyek ini, kita akan mengeksplorasi beberapa variabel saja.

### Data tourism with ID

- dataset ini yang akan kita gunakan dalam membuat model content-based filtering

#### Univariate Exploratory Data Analysis

- menampilkan kolom dari dat_tourism_id
"""

dat_tourism_id.columns.values

"""- menampilkan unik values dari kolom Category"""

# Show unique values from a column
unique_values_cat = dat_tourism_id['Category'].unique()
print(unique_values_cat)

"""- menampilkan unique values dari kolom city"""

# Show unique values from a column
unique_values_city = dat_tourism_id['City'].unique()
print(unique_values_city)

dat_tourism_id.describe().apply(lambda s: s.apply('{0:.2f}'.format))

"""Variabel-variabel pada dat_tourism_id dataset adalah sebagai berikut:

- place_id : id tempat
- place_name : nama tempat
- description : deksripsi singkat tentang objek wisata
- category : kategori tempat wisata dimana terdapat 6 kategori yaitu budaya,taman hiburan, cagar alam, bahari, pusat perbelanjaan, tempat ibadah
- city : kota tempat wisata, pada dataset ini masih terbatas pada 5 kota besar yaitu jakarta, yogyakarta, bandung, semarang, surabaya.
- price : harga masuk ke tempat wisata, dimana range mulai dari 0 (gratis) - 900.000
- rating : penilaian tempat
- time_minutes : waktu tempuh
- coordinate : kordinat lokasi
- lat : latitude
- long : longitude
- unnamed 11
- unnamed 12

terdapat 2 kolom tidak bernama yang tidak diketahui nilainya untuk apa sehinngga lebih baik dihapus saja.

- menampilkan sample 5 data teratas dari dat_tourism_id
"""

dat_tourism_id.head()

"""- menampilkan jumlah baris dan tipe data"""

dat_tourism_id.info()

"""Berdasarkan output di atas, kita dapat mengetahui bahwa file dat_tourism_id memiliki 437 entri.

- melihat nilai null dari tiap kolom
"""

dat_tourism_id.isna().sum()

"""berdasarkan output diatas kolom time_minutes memiliki 232 nilai null

- cek duplicate column
"""

dat_tourism_id.duplicated().sum()

"""- menampilkan distribusi kategori"""

dat_tourism_id.groupby('Category')['Category'].agg('count')

#  Categories Distribution

['Budaya' 'Taman Hiburan' 'Cagar Alam' 'Bahari' 'Pusat Perbelanjaan'
 'Tempat Ibadah']

from pandas.core.tools.datetimes import overload
BDY = dat_tourism_id.loc[dat_tourism_id['Category'] == 'Budaya'].count()[0]
THN = dat_tourism_id.loc[dat_tourism_id['Category'] == 'Taman Hiburan'].count()[0]
CAM = dat_tourism_id.loc[dat_tourism_id['Category'] == 'Cagar Alam'].count()[0]
BAH = dat_tourism_id.loc[dat_tourism_id['Category'] == 'Bahari'].count()[0]
PPA = dat_tourism_id.loc[dat_tourism_id['Category'] == 'Pusat Perbelanjaan'].count()[0]
TIB = dat_tourism_id.loc[dat_tourism_id['Category'] == 'Tempat Ibadah'].count()[0]

labels = ['Budaya','Taman Hiburan','Cagar Alam','Bahari','Pusat Perbelanjaan','Tempat Ibadah']
colors = ['#81F4E1', '#56CBF9', '#F5D491', '#BEB7A4', '#B4E1FF', '#F06C9B']

plt.figure(figsize = (10,7))
plt.title('Categories Distribution')
plt.pie([BDY, THN, CAM, BAH, PPA, TIB],
        labels = labels,
        colors = colors,
        autopct = '%.2f %%'
        )

plt.show()

"""### Data tourism Rating

- dataset ini yang akan kita gunakan sebagai variabel pada model colaborative filtering

#### Univariate Exploratory Data Analysis
"""

dat_tourism_rating.columns.values

"""Variabel-variabel pada dat_tourism_id dataset adalah sebagai berikut:

- user_id : id user
- place_Id :  id tempat wisata
- place_ratings : penilaian tempat wisata

- cek jumlah entry dan tipe data
"""

dat_tourism_rating.info()

"""- melihat statistik deskriptif dari kolom dengan tipe data numerik,"""

dat_tourism_rating.describe().apply(lambda s: s.apply('{0:.2f}'.format))

"""Dataset tempat wisata ini memiliki rating  terendah 1.00 dan rating tertinggi 5.00 dengan rata-rata 3.07.

- melihat distribusi rating
"""

# Anime's Average Ratings Distribution
plt.hist(dat_tourism_rating.Place_Ratings, color='#B4E1FF', edgecolor='black')
plt.ylabel('Total')
plt.xlabel('Avg Rating')
plt.title("Place Average Ratings Distribution")
plt.show()

"""- mengecek nilai null"""

dat_tourism_rating.isna().sum()

"""- menampilkan 5 sample data teratas"""

dat_tourism_rating.head()

"""- menampilkan nama tempat dengn menggabungkan data rating x data id"""

dat_tourism_rating_1 = pd.merge(dat_tourism_rating,dat_tourism_id,on='Place_Id')

user_counts = dat_tourism_rating_1.groupby('Place_Name')['User_Id'].agg('count')

# Mengurutkan data berdasarkan count 'User_Id'
sorted_place_counts = place_counts.sort_values(ascending=False)

# Tampilkan hasil
print(sorted_place_counts)

# Hitung rata-rata count 'User_Id'
mean_place_counts = user_counts.mean()

# Membuat plot visualisasi
plt.figure(figsize=(10, 6))  # Atur ukuran plot sesuai kebutuhan
plt.bar(place_counts.index, place_counts.values)
plt.axhline(mean_place_counts, color='red', linestyle='--', label='Rata-rata')
plt.xlabel('Place_Name')
plt.ylabel('Count User_Id')
plt.title('Count User_Id by Place_Name')
plt.xticks(rotation=90)
plt.legend()
plt.show()

"""berdasarkan data diatas bahwa jumlah penilaian user terbanyak adalah 39 dan terkecil adalah 12 sedangkan rata2 jumlah penilaian tiap tempat berada pada range 20-25

- menampilkan 10 tempat dengan jumlah penilai user terbanyak
"""

user_counts = dat_tourism_rating_1.groupby('Place_Name')['User_Id'].agg('count')

# Ambil 10 data teratas
top_10_places = user_counts.nlargest(10)

# Tampilkan hasil
# print(top_10_places)

# Membuat plot visualisasi
plt.figure(figsize=(10, 6))  # Atur ukuran plot sesuai kebutuhan
plt.barh(top_10_places.index, top_10_places.values)
plt.xlabel('Jumlah User')
plt.ylabel('Place_Name')
plt.title('Top 10 Places by User Count')
plt.show()

"""### Data User

menampilkan sample 5 data teratas
"""

dat_tourism_user.head()

"""Menarik. Kita mendapatkan data lokasi, umur. Jika kita ingin membangun sistem rekomendasi yang lebih kompleks, mungkin kita perlu menyertakan fitur-fitur di atas pada model. Data profile ini berguna jika kita ingin membuat sistem rekomendasi berdasarkan demografi. Namun, untuk studi kasus kali ini, kita tidak akan menggunakan data profile pada model.

- menampilkan jumlah entry, tipe
"""

dat_tourism_user.info()

"""- menampilkan deskripsi kolom yang bertipe angka"""

dat_tourism_user.describe()

"""- melihat distribusi umur user"""

# Anime's Average Ratings Distribution
plt.hist(dat_tourism_user.Age, color='#B4E1FF', edgecolor='black')
plt.ylabel('Total')
plt.xlabel('Avg Age')
plt.title("Age Average Distribution")
plt.show()

"""- melihat distribusi user berdasarkan lokasi"""

dat_tourism_user.groupby('Location')['User_Id'].agg('count')

# Grupkan berdasarkan 'Location' dan hitung jumlah 'User_Id' pada setiap grup
location_counts = dat_tourism_user.groupby('Location')['User_Id'].agg('count')

# Plot bar chart
plt.figure(figsize=(10, 6))  # Atur ukuran plot sesuai kebutuhan
location_counts.plot(kind='bar')
plt.xlabel('Location')
plt.ylabel('Count')
plt.title('User Counts by Location')
# plt.xticks(rotation=45)
plt.show()

"""## Data preparation"""

dat_tourism_rating.isna().sum()

dat_tourism_id.isna().sum()

dat_tourism_user.isna().sum()

dat_tourism_id.drop(['Rating','Time_Minutes','Coordinate','Lat','Long','Unnamed: 11','Unnamed: 12'],axis=1,inplace=True)
dat_tourism_id

dat_rekomendasi = pd.merge(dat_tourism_rating.groupby('Place_Id')['Place_Ratings'].mean(),dat_tourism_id,on='Place_Id')
dat_rekomendasi

dat_rekomendasi.describe()

# Mengurutkan DataFrame berdasarkan nilai tertinggi pada kolom 'ColumnName'
sorted_df = dat_rekomendasi.sort_values('Place_Ratings', ascending=False)

# Menampilkan 10 baris teratas
top_10_rows = sorted_df[['Place_Name','Place_Ratings']].head(10)

# Tampilkan hasil
# print(top_10_rows)

# Membuat plot visualisasi dengan label sumbu x dan y dibalik
plt.figure(figsize=(10, 6))  # Atur ukuran plot sesuai kebutuhan
plt.barh(top_10_rows['Place_Name'], top_10_rows['Place_Ratings'])
plt.xlabel('Ratings')  # Label sumbu x
plt.ylabel('Place')  # Label sumbu y
plt.title('Top 10 Places by Ratings')
plt.show()

"""## Modeling

### modeling with content based filtering

- Dalam pendekatan ini, digunakan metode TF-IDF dan Cosine Similarity untuk memperoleh rekomendasi yang relevan.

import library
- sastrawi untuk nlp processing
- coisine_similarity
- TfidfVectorizer
"""

!pip install Sastrawi

from sklearn.feature_extraction.text import TfidfVectorizer
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
from sklearn.metrics.pairwise import cosine_similarity

"""- define variabel TfidfVectorizer, stem, stopword"""

tv = TfidfVectorizer(max_features=5000)
stem = StemmerFactory().create_stemmer()
stopword = StopWordRemoverFactory().create_stop_word_remover()

"""- membuat fungsi data preprocessing data
  - menggunakan fungsi lower
  - menggunakan fungsi stem
  - menggunakan fungsi stopword
"""

def preprocessing(data):
    data = data.lower()
    data = stem.stem(data)
    data = stopword.remove(data)
    return data

"""- data preparation
  - menyalin dat_rekomendasi
  - membuat kolom baru bernama tags yang merupakan hasil penggabungan kolom description dan kategori
  - menghapus kolom price, place_ratings, description, category, dan city
"""

dat_content_based_filtering = dat_rekomendasi.copy()
dat_content_based_filtering['Tags'] = dat_content_based_filtering['Description'] + ' ' + dat_content_based_filtering['Category']
dat_content_based_filtering.drop(['Price','Place_Ratings','Description','Category','City'],axis=1,inplace=True)
dat_content_based_filtering

"""- data preprocessing (implementasi fungsi preprocessing)"""

dat_content_based_filtering.Tags = dat_content_based_filtering.Tags.apply(preprocessing)
dat_content_based_filtering

"""- implementasi TF-IDF Vectorizer"""

vectors = tv.fit_transform(dat_content_based_filtering.Tags).toarray()
vectors

"""- implementasi Cosine Similarity with vectors inputs and save it as similarity variabel"""

similarity = cosine_similarity(vectors)
similarity[0][1:10]

"""- membuat fungsi content based rekomendasi
  - menggunakan similarity variabel
  - menggunakan fungsi pengurutan
  - menampilkan hasil
"""

def recommend_by_content_based_filtering(nama_tempat):
    nama_tempat_index = dat_content_based_filtering[dat_content_based_filtering['Place_Name']==nama_tempat].index[0]
    distancess = similarity[nama_tempat_index]
    nama_tempat_list = sorted(list(enumerate(distancess)),key=lambda x: x[1],reverse=True)[1:6]

    recommended_nama_tempats = []
    for i in nama_tempat_list:
        recommended_nama_tempats.append([dat_content_based_filtering.iloc[i[0]].Place_Name]+[i[1]])
        # print(nama_tempats.iloc[i[0]].original_title)

    return recommended_nama_tempats

"""#### uji coba fungsi content-based rekomendasi
  - uji coba 3 tempat yaitu Monumen nasioanl, taman bangkul dan atlantis water adventure
"""

recommend_by_content_based_filtering('Monumen Nasional')

recommend_by_content_based_filtering('Taman Bungkul')

recommend_by_content_based_filtering('Atlantis Water Adventure')

"""### modeling with Collaborative filtering

- Pendekatai yang digunakan adalah model based.
 dengan metode deeplearning.
- Digunakan model RecommerderNet berbasis TensorFlow untuk mempelajari pola preferensi pelanggan dan interaksi mereka dengan tempat. Model ini menggunakan embedding untuk merepresentasikan user dan tourism. Penggabungan embedding tersebut untuk dapat memprediksi preferensi user terhadap tempat wisata tertentu.

import library
- tensorflow
- keras
- layers
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""- menyalin data rating"""

dat_collaborative_filtering = dat_tourism_rating.copy()
dat_collaborative_filtering

"""- encoding
  - Encoding ini berguna dalam proses pembuatan model dan perhitungan dalam sistem rekomendasi untuk mempermudah pengolahan data dan komputasi.
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = dat_collaborative_filtering['User_Id'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

# Mengubah placeID menjadi list tanpa nilai yang sama
tourism_ids = dat_collaborative_filtering['Place_Id'].unique().tolist()

# Melakukan proses encoding placeID
tourism_to_tourism_encoded = {x: i for i, x in enumerate(tourism_ids)}

# Melakukan proses encoding angka ke placeID
tourism_encoded_to_tourism = {i: x for i, x in enumerate(tourism_ids)}

"""- Mapping
  - Dengan melakukan mapping ini, nilai userID dan placeID pada dataframe dat_collaborative_filtering akan digantikan dengan nilai encoded userID dan placeID yang digunakan dalam proses pemodelan collaborative filtering. Mapping ini berguna dalam membentuk input data yang sesuai dengan format yang dibutuhkan oleh model dan algoritma collaborative filtering.
"""

# Mapping userID ke dataframe user
dat_collaborative_filtering['user'] = dat_collaborative_filtering['User_Id'].map(user_to_user_encoded)

# Mapping placeID ke dataframe tourism
dat_collaborative_filtering['tourism'] = dat_collaborative_filtering['Place_Id'].map(tourism_to_tourism_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah tourism
num_tourism = len(tourism_encoded_to_tourism)
print(num_tourism)

# Mengubah rating menjadi nilai float
dat_collaborative_filtering['Place_Ratings'] = dat_collaborative_filtering['Place_Ratings'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(dat_collaborative_filtering['Place_Ratings'])

# Nilai maksimal rating
max_rating = max(dat_collaborative_filtering['Place_Ratings'])

print('Number of User: {}, Number of Place: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_tourism, min_rating, max_rating
))

"""Dengan melakukan perhitungan jumlah user dan tempat wisata, serta mengubah tipe data rating ke float32, dan mendapatkan nilai minimum dan maksimum rating, kita dapat memperoleh informasi yang berguna dalam proses pemodelan collaborative filtering.
- data-data tersebut yang selanjutnya akan digunakan pada modeling

- mengacak urutan baris dalam dataframe dat_collaborative_filtering dengan menggunakan fungsi sample()
  - Mengacak urutan baris dalam dataframe seringkali digunakan untuk memastikan bahwa data yang digunakan dalam proses pembelajaran atau pemodelan tidak memiliki pola tertentu atau bias yang terkait dengan urutan data. Ini membantu dalam mencegah atau mengurangi kemungkinan overfitting dan memastikan hasil yang lebih objektif dalam evaluasi model.
"""

dat_collaborative_filtering = dat_collaborative_filtering.sample(frac=1, random_state=42)
dat_collaborative_filtering

"""#### Split data train dan data test

- define variabel input (x) dan variabel output (y)
  - dilakukan juga normalisasi nilai rating pada kolom 'Place_Ratings' dalam dataframe
  - Hasil normalisasi ini berguna dalam pemodelan collaborative filtering, di mana nilai rating yang dinormalisasi dapat digunakan sebagai target variabel (y) dalam proses pembelajaran model. Normalisasi ini memastikan bahwa rentang nilai rating yang diberikan kepada model berada dalam skala yang seragam dan mempermudah proses perhitungan dan optimisasi pada model.
"""

# Membuat variabel y untuk membuat rating dari hasil
y = dat_collaborative_filtering['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

x = dat_collaborative_filtering[['user', 'tourism']].values

"""- membagi dataset menjadi data training dan data validasi dengan perbadingan 80:20"""

train_indices = int(0.8 * dat_collaborative_filtering.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""#### Training

- membuat model
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_tourism, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_tourism = num_tourism
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.tourism_embedding = layers.Embedding( # layer embeddings tourism
        num_tourism,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.tourism_bias = layers.Embedding(num_tourism, 1) # layer embedding tourism bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    tourism_vector = self.tourism_embedding(inputs[:, 1]) # memanggil layer embedding 3
    tourism_bias = self.tourism_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_tourism = tf.tensordot(user_vector, tourism_vector, 2)

    x = dot_user_tourism + user_bias + tourism_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""- compile model"""

model = RecommenderNet(num_users, num_tourism, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""- melakukan training pada model"""

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""#### mendapatkan rekomendasi

- mengambil sample user
"""

tourism_df = dat_tourism_id
df = dat_tourism_rating

# Mengambil sample user
user_id = df.User_Id.sample(1).iloc[0]
tourism_visited_by_user = df[df.User_Id == user_id]

"""- operasi pada dataframe tourism_df untuk mendapatkan tempat wisata yang belum dikunjungi oleh sample pengguna yang kita dapatkan sebelumnya."""

tourism_not_visited = tourism_df[~tourism_df['Place_Id'].isin(tourism_visited_by_user.Place_Id.values)]['Place_Id']
tourism_not_visited = list(
    set(tourism_not_visited)
    .intersection(set(tourism_to_tourism_encoded.keys()))
)

tourism_not_visited = [[tourism_to_tourism_encoded.get(x)] for x in tourism_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_tourism_array = np.hstack(
    ([[user_encoder]] * len(tourism_not_visited), tourism_not_visited)
)

"""- melakukan prediksi rating menggunakan model yang telah kita latih untuk mengetahui rating dari tempat wisata yang belum dikunjungi oleh sample user tersebut."""

ratings = model.predict(user_tourism_array).flatten()

"""- mendapatkan daftar tempat wisata yang direkomendasikan berdasarkan hasil prediksi rating teratas."""

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_tourism_ids = [
    tourism_encoded_to_tourism.get(tourism_not_visited[x][0]) for x in top_ratings_indices
]

"""- menampilkan hasil rekomendasi"""

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('tourism with high ratings from user')
print('----' * 8)

top_tourism_user = (
    tourism_visited_by_user.sort_values(
        by = 'Place_Ratings',
        ascending=False
    )
    .head(5)
    .Place_Id.values
)

tourism_df_rows = tourism_df[tourism_df['Place_Id'].isin(top_tourism_user)]
for row in tourism_df_rows.itertuples():
    print(row.Place_Name)

print('----' * 8)
print('Top 10 tourism recommendation')
print('----' * 8)

recommended_tourism = tourism_df[tourism_df['Place_Id'].isin(recommended_tourism_ids)]
for row in recommended_tourism.itertuples():
    print(row.Place_Name)